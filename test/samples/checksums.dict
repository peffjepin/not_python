{'debug_tokens': {'test/samples/tokenization/comments.py': 'f5438ae20b92e6ab7800f955bbe2b2e8', 'test/samples/tokenization/for_loop.py': '0f5352d3970992c1d442aae1ba029889', 'test/samples/tokenization/strings.py': 'cb2f106d0242de858c69cf7cace456b9', 'test/samples/tokenization/lists.py': '90c96942cc7db3de51cfa25577334a05', 'test/samples/tokenization/numbers.py': 'c34b355aea9a352195aea84b618b6e7b'}, 'debug_statements': {'test/samples/statements/expressions.py': 'b1a44fbae5ece8b397290def50ce2290'}}